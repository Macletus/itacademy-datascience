{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9417e3-d091-497d-ad9e-bccb3f77f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ce71526-9e04-42d6-ab13-b5e439f56956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "data_path = 'D:/Sistema_Solar/Python/itacademy/sprint10/data/'\n",
    "data_path = Path(data_path)\n",
    "\n",
    "output_path = 'D:/Sistema_Solar/Python/itacademy/itacademy-datascience/sprint10/output/'\n",
    "output_path = Path(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ce609-5a0f-4bfa-9104-b2131e345b55",
   "metadata": {},
   "source": [
    "- **Exercici 1**\n",
    "\n",
    "Realitza web scraping de dues de les tres pàgines web proposades utilitzant BeautifulSoup primer i Selenium després. \n",
    "\n",
    "http://quotes.toscrape.com\n",
    "\n",
    "https://www.bolsamadrid.es\n",
    "\n",
    "www.wikipedia.es (fes alguna cerca primer i escrapeja algun contingut)\n",
    "\n",
    "\n",
    "\n",
    "- **Exercici 2**\n",
    "\n",
    "Documenta en un Word el teu conjunt de dades generat amb la informació que tenen els diferents arxius de Kaggle.\n",
    "\n",
    " Per saber més\n",
    "\n",
    "A manera d'exemple del que es demana pots consultar aquest enllaç:\n",
    "\n",
    "->https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats.\n",
    "\n",
    "\n",
    "\n",
    "- **Exercici 3**\n",
    "\n",
    "Tria una pàgina web que tu vulguis i realitza web scraping mitjançant la llibreria Selenium primer i Scrapy després. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c07f6a-93fd-4865-a22d-a77da6d7e58c",
   "metadata": {},
   "source": [
    "Comencem amb una web sencilla, http://quotes.toscrape.com amb BeatifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a6f036-51f5-4078-8ced-70cbf58fa032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text              autor  \\\n",
      "0  “The world as we have created it is a process ...    Albert Einstein   \n",
      "1  “It is our choices, Harry, that show what we t...       J.K. Rowling   \n",
      "2  “There are only two ways to live your life. On...    Albert Einstein   \n",
      "3  “The person, be it gentleman or lady, who has ...        Jane Austen   \n",
      "4  “Imperfection is beauty, madness is genius and...     Marilyn Monroe   \n",
      "5  “Try not to become a man of success. Rather be...    Albert Einstein   \n",
      "6  “It is better to be hated for what you are tha...         André Gide   \n",
      "7  “I have not failed. I've just found 10,000 way...   Thomas A. Edison   \n",
      "8  “A woman is like a tea bag; you never know how...  Eleanor Roosevelt   \n",
      "9  “A day without sunshine is like, you know, nig...       Steve Martin   \n",
      "\n",
      "                                             tags  \n",
      "0        [change, deep-thoughts, thinking, world]  \n",
      "1                            [abilities, choices]  \n",
      "2  [inspirational, life, live, miracle, miracles]  \n",
      "3              [aliteracy, books, classic, humor]  \n",
      "4                    [be-yourself, inspirational]  \n",
      "5                     [adulthood, success, value]  \n",
      "6                                    [life, love]  \n",
      "7   [edison, failure, inspirational, paraphrased]  \n",
      "8               [misattributed-eleanor-roosevelt]  \n",
      "9                        [humor, obvious, simile]  \n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Albert Einstein\n",
      "['change', 'deep-thoughts', 'thinking', 'world']\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "J.K. Rowling\n",
      "['abilities', 'choices']\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Albert Einstein\n",
      "['inspirational', 'life', 'live', 'miracle', 'miracles']\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Jane Austen\n",
      "['aliteracy', 'books', 'classic', 'humor']\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Marilyn Monroe\n",
      "['be-yourself', 'inspirational']\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "Albert Einstein\n",
      "['adulthood', 'success', 'value']\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "André Gide\n",
      "['life', 'love']\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Thomas A. Edison\n",
      "['edison', 'failure', 'inspirational', 'paraphrased']\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Eleanor Roosevelt\n",
      "['misattributed-eleanor-roosevelt']\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "Steve Martin\n",
      "['humor', 'obvious', 'simile']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "data_path = 'D:/Sistema_Solar/Python/itacademy/sprint10/data/'\n",
    "data_path = Path(data_path)\n",
    "\n",
    "output_path = 'D:/Sistema_Solar/Python/itacademy/itacademy-datascience/sprint10/output/'\n",
    "output_path = Path(output_path)\n",
    "\n",
    "# Fem la petició a la web\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "# Creem objecte beautifulsoup\n",
    "page_content  = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Cerquem les dades de la web que contenen les cites\n",
    "quotes = page_content.find_all(\"div\", {\"class\": \"quote\"})\n",
    "\n",
    "quotes_list = []\n",
    "\n",
    "for quote in quotes:\n",
    "    text = quote.find(\"span\", {\"class\": \"text\"}).text\n",
    "    author = quote.find(\"small\", {\"class\": \"author\"}).text\n",
    "    tags = [tag.text for tag in quote.find_all(\"a\", {\"class\": \"tag\"})]\n",
    "    \n",
    "    quotes_list.append([text, author, tags])\n",
    "    \n",
    "df = pd.DataFrame(quotes_list, columns=[\"text\", \"autor\", \"tags\"])\n",
    "\n",
    "df.to_csv(output_path / 'quotes_beautiful.csv', index=False)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"autor\"])\n",
    "    print(row[\"tags\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66354c61-02db-4505-b3db-5cc57d12cb69",
   "metadata": {},
   "source": [
    "En el cas d'utilitzar Selenium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f74a6f4-d513-4766-8f17-04a6fb70bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Albert Einstein\n",
      "['change', 'deep-thoughts', 'thinking', 'world']\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "J.K. Rowling\n",
      "['abilities', 'choices']\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Albert Einstein\n",
      "['inspirational', 'life', 'live', 'miracle', 'miracles']\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Jane Austen\n",
      "['aliteracy', 'books', 'classic', 'humor']\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Marilyn Monroe\n",
      "['be-yourself', 'inspirational']\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "Albert Einstein\n",
      "['adulthood', 'success', 'value']\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "André Gide\n",
      "['life', 'love']\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Thomas A. Edison\n",
      "['edison', 'failure', 'inspirational', 'paraphrased']\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Eleanor Roosevelt\n",
      "['misattributed-eleanor-roosevelt']\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "Steve Martin\n",
      "['humor', 'obvious', 'simile']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Inicialitzem el servei de Microsoft Edge\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.63'\n",
    "edge_driver_path = os.path.join(os.getcwd(), 'msedgedriver.exe')\n",
    "edge_service = Service(edge_driver_path)\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(f'user-agent={user_agent}')\n",
    "browser = webdriver.Edge(service=edge_service, options=edge_options)\n",
    "\n",
    "# Fem la petició a la web\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "browser.get(url)\n",
    "\n",
    "# Obtenim les cites\n",
    "quotes = browser.find_elements(By.XPATH, \"//div[@class='quote']\")\n",
    "\n",
    "# Separem les cites i creem dataframe\n",
    "quotes_list = []\n",
    "for quote in quotes:\n",
    "    text = quote.find_element(By.XPATH, \"./span[@class='text']\").text\n",
    "    author = quote.find_element(By.XPATH, \"./span/small[@class='author']\").text\n",
    "    tags = [tag.text for tag in quote.find_elements(By.XPATH, \"./div[@class='tags']/a[@class='tag']\")]\n",
    "    quotes_list.append([text, author, tags])\n",
    "\n",
    "df = pd.DataFrame(quotes_list, columns=[\"text\", \"author\", \"tags\"])\n",
    "\n",
    "df.to_csv(output_path / 'quotes_selenium.csv', index=False)\n",
    "\n",
    "# Imprimir cada fila del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"author\"])\n",
    "    print(row[\"tags\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07656086-f9e1-478f-9b95-0d68db22026e",
   "metadata": {},
   "source": [
    "En el cas de la web, https://www.bolsamadrid.es, podem provar a descarregar la taula de dades de cotizacions de la web del Ibex 35. Caldrà utilizar Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a17350-b79f-4dad-aa73-98dc88918bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Índice    Último  % Dif.    Máximo    Mínimo       Fecha      Hora  \\\n",
      "0  IBEX 35®  8.719,30  -1,92%  9.027,40  8.655,30  17/03/2023  17:38:00   \n",
      "\n",
      "  % Dif. Año  \n",
      "0      5,96%  \n",
      "          Nombre    Último  % Dif.    Máximo    Mínimo      Volumen  \\\n",
      "0        ACCIONA  177,0000   0,45%  180,4000  175,0000      186.030   \n",
      "1   ACCIONA ENER   34,1400  -2,79%   35,3200   33,9600      734.852   \n",
      "2       ACERINOX    8,9820  -0,58%    9,3960    8,9580    1.964.829   \n",
      "3            ACS   28,1600  -1,09%   28,7300   27,7900    4.329.498   \n",
      "4           AENA  142,4000  -4,08%  149,5000  141,6000      462.757   \n",
      "5        AMADEUS   58,3200  -1,82%   60,0400   58,3000    1.439.989   \n",
      "6    ARCELORMIT.   25,0000  -1,69%   26,6350   24,9050      525.117   \n",
      "7    B.SANTANDER    3,1385  -4,65%    3,3855    3,1045  210.488.095   \n",
      "8    BA.SABADELL    0,9826  -3,14%    1,0555    0,9670   79.552.197   \n",
      "9      BANKINTER    5,4200  -2,52%    5,6920    5,3060    7.102.829   \n",
      "10          BBVA    6,0360  -3,49%    6,4050    5,9670   40.145.383   \n",
      "11     CAIXABANK    3,5100  -2,12%    3,6960    3,4720   45.604.721   \n",
      "12       CELLNEX   34,1000  -3,45%   35,4100   33,8500    2.852.473   \n",
      "13        ENAGAS   17,0750  -1,10%   17,5650   17,0200    2.441.199   \n",
      "14        ENDESA   18,5250  -1,44%   18,9850   18,2900   20.132.837   \n",
      "15     FERROVIAL   26,5100  -0,71%   26,9000   26,2000    2.745.084   \n",
      "16       FLUIDRA   16,0700  -1,47%   16,6400   15,8500    2.169.672   \n",
      "17  GRIFOLS CL.A    8,8000  -1,74%    9,3420    8,8000    3.698.258   \n",
      "18           IAG    1,5195  -2,53%    1,5975    1,5080   18.339.412   \n",
      "19     IBERDROLA   10,9200  -1,18%   11,1200   10,8400   40.888.309   \n",
      "20       INDITEX   28,6300  -0,49%   29,2300   28,3200    6.404.695   \n",
      "21       INDRA A   11,2200  -1,32%   11,5900   11,1400    1.044.756   \n",
      "22  INM.COLONIAL    5,8100  -0,77%    5,9450    5,7350    2.587.146   \n",
      "23       LOGISTA   22,2800  -0,09%   22,5400   22,1600      585.118   \n",
      "24        MAPFRE    1,8010  -1,69%    1,8720    1,7860    9.960.586   \n",
      "25  MELIA HOTELS    5,6950  -4,45%    6,0900    5,6500    1.614.780   \n",
      "26        MERLIN    8,1150  -1,70%    8,3200    8,0600    1.771.056   \n",
      "27       NATURGY   26,6600  -0,49%   26,9800   26,2800    2.041.218   \n",
      "28        R.E.C.   15,4250  -1,15%   15,7950   15,3700    3.491.601   \n",
      "29        REPSOL   13,4850   1,35%   13,8350   13,3200    9.322.325   \n",
      "30          ROVI   39,5400  -0,55%   40,3000   39,1800      143.737   \n",
      "31         SACYR    2,7920  -2,10%    2,8840    2,7840    2.853.278   \n",
      "32       SOLARIA   16,8850  -0,91%   17,2850   16,7500      634.708   \n",
      "33    TELEFONICA    3,7020  -0,54%    3,7600    3,6720   82.031.339   \n",
      "34       UNICAJA    0,9875  -1,74%    1,0350    0,9770   15.825.028   \n",
      "\n",
      "   Efectivo (miles €)       Fecha    Hora  \n",
      "0           32.933,12  17/03/2023  Cierre  \n",
      "1           25.137,00  17/03/2023  Cierre  \n",
      "2           17.853,77  17/03/2023  Cierre  \n",
      "3          121.927,04  17/03/2023  Cierre  \n",
      "4           66.186,00  17/03/2023  Cierre  \n",
      "5           84.238,43  17/03/2023  Cierre  \n",
      "6           13.445,64  17/03/2023  Cierre  \n",
      "7          675.770,88  17/03/2023  Cierre  \n",
      "8           79.491,59  17/03/2023  Cierre  \n",
      "9           38.944,49  17/03/2023  Cierre  \n",
      "10         243.611,23  17/03/2023  Cierre  \n",
      "11         161.190,86  17/03/2023  Cierre  \n",
      "12          98.376,16  17/03/2023  Cierre  \n",
      "13          41.835,76  17/03/2023  Cierre  \n",
      "14         372.881,00  17/03/2023  Cierre  \n",
      "15          72.768,24  17/03/2023  Cierre  \n",
      "16          34.946,28  17/03/2023  Cierre  \n",
      "17          33.130,82  17/03/2023  Cierre  \n",
      "18          28.236,94  17/03/2023  Cierre  \n",
      "19         446.865,29  17/03/2023  Cierre  \n",
      "20         182.781,71  17/03/2023  Cierre  \n",
      "21          11.783,94  17/03/2023  Cierre  \n",
      "22          15.054,06  17/03/2023  Cierre  \n",
      "23          13.051,15  17/03/2023  Cierre  \n",
      "24          18.033,29  17/03/2023  Cierre  \n",
      "25           9.422,20  17/03/2023  Cierre  \n",
      "26          14.432,36  17/03/2023  Cierre  \n",
      "27          54.376,04  17/03/2023  Cierre  \n",
      "28          53.989,81  17/03/2023  Cierre  \n",
      "29         126.187,01  17/03/2023  Cierre  \n",
      "30           5.700,77  17/03/2023  Cierre  \n",
      "31           8.040,32  17/03/2023  Cierre  \n",
      "32          10.746,47  17/03/2023  Cierre  \n",
      "33         304.698,75  17/03/2023  Cierre  \n",
      "34          15.821,05  17/03/2023  Cierre  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "# Inicialitzem el servei de Microsoft Edge\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.63'\n",
    "edge_driver_path = os.path.join(os.getcwd(), 'msedgedriver.exe')\n",
    "edge_service = Service(edge_driver_path)\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(f'user-agent={user_agent}')\n",
    "browser = webdriver.Edge(service=edge_service, options=edge_options)\n",
    "\n",
    "edge_options.use_chromium = True\n",
    "edge_options.add_argument(\"--start-maximized\")\n",
    "edge_options.add_argument(\"--disable-extensions\")\n",
    "edge_options.add_argument(\"--disable-gpu\")\n",
    "edge_options.add_argument(\"--disable-infobars\")\n",
    "edge_options.add_argument(\"--headless\")\n",
    "\n",
    "# Carpeta donde se guardará el archivo CSV\n",
    "output_path = 'D:/Sistema_Solar/Python/itacademy/itacademy-datascience/sprint10/output/'\n",
    "output_path = Path(output_path)\n",
    "\n",
    "# Carpeta donde se guardará el archivo CSV\n",
    "data_path = 'D:/Sistema_Solar/Python/itacademy/sprint10/data/'\n",
    "data_path = Path(data_path)\n",
    "\n",
    "download_folder = data_path\n",
    "\n",
    "# Fem la petició a la web\n",
    "url = \"https://www.bolsasymercados.es/bme-exchange/es/Mercados-y-Cotizaciones/Acciones/Mercado-Continuo/Precios/ibex-35-ES0SI0000005\"\n",
    "browser.get(url)\n",
    "\n",
    "# Obtenim les dades del índex\n",
    "rows = []\n",
    "catch = 0\n",
    "while len(rows) == 0: # En ocasions no es descarrega cap informació, eviem que això ocorrega comprovant que rows no està buit\n",
    "    if catch < 10:\n",
    "        table = browser.find_elements(by= By.XPATH, value = '//*[contains(@class,\"index-table\")]//tr')\n",
    "        for row in table:\n",
    "            data = [item.text for item in row.find_elements(by= By.XPATH, value= \".//*[self::td or self::th]\")]\n",
    "            rows.append(data)\n",
    "    else:\n",
    "        pass\n",
    "    catch +=1\n",
    "\n",
    "ibex35 = pd.DataFrame(rows[1:], columns = rows[0])\n",
    "print(ibex35)\n",
    "\n",
    "# Obtenim les dades dels valors que componen el índex\n",
    "rows = []\n",
    "while len(rows) == 0:\n",
    "    if catch < 10:\n",
    "        table = browser.find_elements(by= By.XPATH, value = '//*[contains(@class,\"shares-table\")]//tr')\n",
    "        for row in table:\n",
    "            data = [item.text for item in row.find_elements(by= By.XPATH, value= \".//*[self::td or self::th]\")]\n",
    "            rows.append(data)\n",
    "    else:\n",
    "        pass\n",
    "    catch +=1\n",
    "        \n",
    "# la primera filera és la que pertany als noms de les columnes\n",
    "stock_indices = pd.DataFrame(rows[1:], columns = rows[0])\n",
    "print(stock_indices)\n",
    "\n",
    "# Guardem els dataframes en un .csv\n",
    "ibex35.to_csv(output_path / \"ibex35.csv\", index=False)\n",
    "stock_indices.to_csv(output_path / \"stock_indices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9e1df-7fc6-4a66-9a23-04187dd04adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(stock_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370558fa-5433-46ee-a20e-05c6ff725004",
   "metadata": {},
   "source": [
    "Finalment, provarem també a descarregar informació de taules que podem trobar a la wikipedia, com es el cas de les taules de dades climàtiques de diferents ciutats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "134da4d1-5247-4797-8314-1eb4f555d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Fem la petició a la web\n",
    "url = \"https://en.wikipedia.org/wiki/Valencia\"\n",
    "page = requests.get(url)\n",
    "\n",
    "# Creem objecte beautifulsoup\n",
    "page_content  = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Cerquem la taula en la web\n",
    "table = page_content.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Creem dataframe\n",
    "rows = table.find_all(\"tr\")\n",
    "data = []\n",
    "columns = []\n",
    "index_names = []\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "    # Obtenim les cel·les que ens interessen.\n",
    "    head = row.find_all(\"th\") # Conté els noms de les columnes i el de les files\n",
    "    cells = row.find_all(\"td\")\n",
    "    \n",
    "    # Processem els noms de les columnes i el de les files\n",
    "    if head:\n",
    "        row_values = [cell.text.strip() for cell in head]\n",
    "        if 'Jan' in row_values:\n",
    "            months = row_values\n",
    "        elif len(row_values[0]) < 40:\n",
    "            index_names.append(row_values)\n",
    "    \n",
    "    # Processem els valors de les cel·les\n",
    "    if cells:\n",
    "        row_values = [cell.text.strip() for cell in cells]\n",
    "        if 'Source' not in row_values[0]:\n",
    "            data.append(row_values)\n",
    "        \n",
    "\n",
    "months = [months for months in months if 'Month' not in months]\n",
    "\n",
    "# Convertim les llistes en dataframe i el descarreguem en un csv\n",
    "index_names_l = list(itertools.chain.from_iterable(index_names))\n",
    "df = pd.DataFrame(data, index=index_names_l, columns=months)\n",
    "\n",
    "df.to_csv(output_path / \"valencia_climate_data.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09c830-2267-4b88-8881-b5dbcaf88788",
   "metadata": {},
   "source": [
    "#### Exercici 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfdda4-1a87-48d8-ac3e-3bbda6fbae55",
   "metadata": {},
   "source": [
    "A la web de l'Aemet publiquen mapes sinoptics. En concret, l'anàlisis i la predicció fins a 48 hores. I aquesta s'actualitza dos voltes cada dia. Aemet no ofereix la possibilitat de descarregar les dades pero es podria automatitzar la descàrrega dels mapes tant amb Selenium com amb Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "93432bc4-7fe5-4f36-b4d1-d060f1629058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapa 2023031812+000_ww_gpx0a200.gif descarregat.\n",
      "Mapa 2023031812+012_ww_g1x0a212.gif descarregat.\n",
      "Mapa 2023031812+024_ww_g1x0a2d1.gif descarregat.\n",
      "Mapa 2023031812+036_ww_g1x0a2c1.gif descarregat.\n",
      "Mapa 2023031812+048_ww_g1x0a2d2.gif descarregat.\n",
      "Mapa 2023031812+060_ww_g1x0a2c2.gif descarregat.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "\n",
    "# Configurar el driver de Selenium\n",
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://www.aemet.es/ca/eltiempo/prediccion/mapa_frentes\")\n",
    "\n",
    "# encontrar todos los elementos de imagen con clase \"lazyOwl\"\n",
    "enlaces = driver.find_elements(by=By.CSS_SELECTOR, value=\"img.lazyOwl\")\n",
    "\n",
    "# crear una carpeta para las imágenes\n",
    "if not os.path.exists(\"mapas\"):\n",
    "    os.mkdir(\"mapas\")\n",
    "\n",
    "for i in range(len(enlaces)):\n",
    "    enlace = enlaces[i]\n",
    "    if i==0 or i==5:\n",
    "        # obtener la URL de la imagen desde el atributo \"src\"\n",
    "        url_map = enlace.get_attribute(\"src\")\n",
    "    else:\n",
    "        # obtener la URL de la imagen desde el atributo \"src\"\n",
    "        url_map = enlace.get_attribute(\"data-src\")\n",
    "        url_map = 'https://www.aemet.es' + url_map \n",
    "\n",
    "    file_name = url_map.split(\"/\")[-1]\n",
    "\n",
    "    file_path = \"mapes_selenium/\" + file_name\n",
    "    output_map = output_path / file_path\n",
    "    output_map = Path(output_map)\n",
    "    with open(output_map, \"wb\") as archivo:\n",
    "        archivo.write(requests.get(url_map).content)\n",
    "        print(f\"Mapa {file_name} descarregat.\")\n",
    "        \n",
    "# cerrar el driver de Selenium\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e249f3a-b3a6-4991-9ab0-cfc508c8d728",
   "metadata": {},
   "source": [
    "Ara adaptarem el codi a Scrapy. Per a això, crearem en el directori on tenim l'arxiu del notebook jupyter, el codi a executar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f9117f31-9fe1-4fd4-92fb-9c9a07a5028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = 'D:/Sistema_Solar/Python/itacademy/itacademy-datascience/sprint10/output/'\n",
    "output_path = Path(output_path)\n",
    "\n",
    "class AEMETSpider(scrapy.Spider):\n",
    "    name = 'aemet_spider'\n",
    "    start_urls = ['https://www.aemet.es/ca/eltiempo/prediccion/mapa_frentes']\n",
    "\n",
    "    # Configuració per optimitzar les peticions\n",
    "    custom_settings = {\n",
    "        'CONCURRENT_REQUESTS': 1, # Evite fer massa peticions a la vegada\n",
    "        'AUTOTHROTTLE_ENABLED': True, # Controla la velocitat de les peticions\n",
    "        'DOWNLOAD_DELAY': 1 # Temps entre peticions\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        enlaces = response.css(\"img.lazyOwl\")\n",
    "\n",
    "        for enlace in enlaces:\n",
    "\n",
    "            url_map = enlace.attrib[\"data-src\"]\n",
    "            url_map = 'https://www.aemet.es' + url_map\n",
    "\n",
    "            file_name = url_map.split(\"/\")[-1]\n",
    "\n",
    "            file_path = \"mapes_scrapy/\" + file_name\n",
    "            output_map = output_path / file_path\n",
    "            print(output_map)\n",
    "            output_map = Path(output_map)\n",
    "            with open(output_map, \"wb\") as archivo:\n",
    "                archivo.write(requests.get(url_map).content)\n",
    "                print(f\"Mapa {file_name} descarregat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3ef39517-c885-4db1-a666-681631ad1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Sistema_Solar\\Python\\itacademy\\itacademy-datascience\\sprint10\\output\\mapes_scrapy\\2023031812+000_ww_gpx0a200.gif\n",
      "Mapa 2023031812+000_ww_gpx0a200.gif descarregat.\n",
      "D:\\Sistema_Solar\\Python\\itacademy\\itacademy-datascience\\sprint10\\output\\mapes_scrapy\\2023031812+012_ww_g1x0a212.gif\n",
      "Mapa 2023031812+012_ww_g1x0a212.gif descarregat.\n",
      "D:\\Sistema_Solar\\Python\\itacademy\\itacademy-datascience\\sprint10\\output\\mapes_scrapy\\2023031812+024_ww_g1x0a2d1.gif\n",
      "Mapa 2023031812+024_ww_g1x0a2d1.gif descarregat.\n",
      "D:\\Sistema_Solar\\Python\\itacademy\\itacademy-datascience\\sprint10\\output\\mapes_scrapy\\2023031812+036_ww_g1x0a2c1.gif\n",
      "Mapa 2023031812+036_ww_g1x0a2c1.gif descarregat.\n",
      "D:\\Sistema_Solar\\Python\\itacademy\\itacademy-datascience\\sprint10\\output\\mapes_scrapy\\2023031812+048_ww_g1x0a2d2.gif\n",
      "Mapa 2023031812+048_ww_g1x0a2d2.gif descarregat.\n",
      "D:\\Sistema_Solar\\Python\\itacademy\\itacademy-datascience\\sprint10\\output\\mapes_scrapy\\2023031812+060_ww_g1x0a2c2.gif\n",
      "Mapa 2023031812+060_ww_g1x0a2c2.gif descarregat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 20:18:31 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scrapybot)\n",
      "2023-03-18 20:18:31 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.7.0, w3lib 1.21.0, Twisted 22.2.0, Python 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1t  7 Feb 2023), cryptography 38.0.4, Platform Windows-10-10.0.19045-SP0\n",
      "2023-03-18 20:18:31 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'AUTOTHROTTLE_ENABLED': True,\n",
      " 'CONCURRENT_REQUESTS': 1,\n",
      " 'DOWNLOAD_DELAY': 1,\n",
      " 'SPIDER_LOADER_WARN_ONLY': True}\n",
      "2023-03-18 20:18:31 [py.warnings] WARNING: D:\\Programes\\Anaconda3\\lib\\site-packages\\scrapy\\utils\\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-03-18 20:18:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2023-03-18 20:18:31 [scrapy.extensions.telnet] INFO: Telnet Password: c23812bf479ba0b9\n",
      "2023-03-18 20:18:31 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats',\n",
      " 'scrapy.extensions.throttle.AutoThrottle']\n",
      "2023-03-18 20:18:33 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-03-18 20:18:33 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-03-18 20:18:33 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-03-18 20:18:33 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-03-18 20:18:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-03-18 20:18:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-03-18 20:18:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.aemet.es/ca/eltiempo/prediccion/mapa_frentes> (referer: None)\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023031812+000_ww_gpx0a200.gif HTTP/1.1\" 200 129720\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023031812+012_ww_g1x0a212.gif HTTP/1.1\" 200 144827\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023031812+024_ww_g1x0a2d1.gif HTTP/1.1\" 200 141376\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023031812+036_ww_g1x0a2c1.gif HTTP/1.1\" 200 140450\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023031812+048_ww_g1x0a2d2.gif HTTP/1.1\" 200 139700\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-18 20:18:34 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023031812+060_ww_g1x0a2c2.gif HTTP/1.1\" 200 140453\n",
      "2023-03-18 20:18:35 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-03-18 20:18:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 257,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 10775,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 1.050314,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 3, 18, 19, 18, 35, 37800),\n",
      " 'httpcompression/response_bytes': 49292,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/DEBUG': 14,\n",
      " 'log_count/INFO': 10,\n",
      " 'log_count/WARNING': 1,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2023, 3, 18, 19, 18, 33, 987486)}\n",
      "2023-03-18 20:18:35 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider -a file_path=aemet_spider.py aemet_spider.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca921c-2e29-477e-9741-4d9f74a36101",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'D:/Sistema_Solar/Python/itacademy/itacademy-datascience/sprint10/output/'\n",
    "output_path = Path(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
