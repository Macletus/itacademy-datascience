{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df53b76-9281-415b-b757-68c66a6afc56",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1><center>Sprint 10</center></h1>\n",
    "<h2><center>Tasca 1: Exercicis de Web Scraping..</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e59946-e915-421e-bfea-fc01c687dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import selenium.webdriver as webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce71526-9e04-42d6-ab13-b5e439f56956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "data_path = 'D:/Sistema_Solar/Python/itacademy/sprint10/data/'\n",
    "data_path = Path(data_path)\n",
    "\n",
    "output_path = 'D:/Sistema_Solar/Python/itacademy/itacademy-datascience/sprint10/output/'\n",
    "output_path = Path(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ce609-5a0f-4bfa-9104-b2131e345b55",
   "metadata": {},
   "source": [
    "- **Exercici 1**\n",
    "\n",
    "Realitza web scraping de dues de les tres pàgines web proposades utilitzant BeautifulSoup primer i Selenium després. \n",
    "\n",
    "http://quotes.toscrape.com\n",
    "\n",
    "https://www.bolsamadrid.es\n",
    "\n",
    "www.wikipedia.es (fes alguna cerca primer i escrapeja algun contingut)\n",
    "\n",
    "\n",
    "\n",
    "- **Exercici 2**\n",
    "\n",
    "Documenta en un Word el teu conjunt de dades generat amb la informació que tenen els diferents arxius de Kaggle.\n",
    "\n",
    " Per saber més\n",
    "\n",
    "A manera d'exemple del que es demana pots consultar aquest enllaç:\n",
    "\n",
    "->https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats.\n",
    "\n",
    "\n",
    "\n",
    "- **Exercici 3**\n",
    "\n",
    "Tria una pàgina web que tu vulguis i realitza web scraping mitjançant la llibreria Selenium primer i Scrapy després. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c07f6a-93fd-4865-a22d-a77da6d7e58c",
   "metadata": {},
   "source": [
    "Comencem amb una web sencilla, http://quotes.toscrape.com amb BeatifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a6f036-51f5-4078-8ced-70cbf58fa032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Albert Einstein\n",
      "['change', 'deep-thoughts', 'thinking', 'world']\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "J.K. Rowling\n",
      "['abilities', 'choices']\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Albert Einstein\n",
      "['inspirational', 'life', 'live', 'miracle', 'miracles']\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Jane Austen\n",
      "['aliteracy', 'books', 'classic', 'humor']\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Marilyn Monroe\n",
      "['be-yourself', 'inspirational']\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "Albert Einstein\n",
      "['adulthood', 'success', 'value']\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "André Gide\n",
      "['life', 'love']\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Thomas A. Edison\n",
      "['edison', 'failure', 'inspirational', 'paraphrased']\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Eleanor Roosevelt\n",
      "['misattributed-eleanor-roosevelt']\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "Steve Martin\n",
      "['humor', 'obvious', 'simile']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fem la petició a la web\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "# Creem objecte beautifulsoup\n",
    "page_content  = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Cerquem les dades de la web que contenen les cites\n",
    "quotes = page_content.find_all(\"div\", {\"class\": \"quote\"})\n",
    "\n",
    "quotes_list = []\n",
    "\n",
    "for quote in quotes:\n",
    "    text = quote.find(\"span\", {\"class\": \"text\"}).text\n",
    "    author = quote.find(\"small\", {\"class\": \"author\"}).text\n",
    "    tags = [tag.text for tag in quote.find_all(\"a\", {\"class\": \"tag\"})]\n",
    "    \n",
    "    quotes_list.append([text, author, tags])\n",
    "    \n",
    "df = pd.DataFrame(quotes_list, columns=[\"text\", \"autor\", \"tags\"])\n",
    "\n",
    "df.to_csv(output_path / 'quotes_beautiful.csv', index=False)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"autor\"])\n",
    "    print(row[\"tags\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66354c61-02db-4505-b3db-5cc57d12cb69",
   "metadata": {},
   "source": [
    "En el cas d'utilitzar Selenium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f74a6f4-d513-4766-8f17-04a6fb70bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Albert Einstein\n",
      "['change', 'deep-thoughts', 'thinking', 'world']\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "J.K. Rowling\n",
      "['abilities', 'choices']\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Albert Einstein\n",
      "['inspirational', 'life', 'live', 'miracle', 'miracles']\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Jane Austen\n",
      "['aliteracy', 'books', 'classic', 'humor']\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Marilyn Monroe\n",
      "['be-yourself', 'inspirational']\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "Albert Einstein\n",
      "['adulthood', 'success', 'value']\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "André Gide\n",
      "['life', 'love']\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Thomas A. Edison\n",
      "['edison', 'failure', 'inspirational', 'paraphrased']\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Eleanor Roosevelt\n",
      "['misattributed-eleanor-roosevelt']\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "Steve Martin\n",
      "['humor', 'obvious', 'simile']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem el servei de Microsoft Edge\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.63'\n",
    "edge_driver_path = os.path.join(os.getcwd(), 'msedgedriver.exe')\n",
    "edge_service = Service(edge_driver_path)\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(f'user-agent={user_agent}')\n",
    "browser = webdriver.Edge(service=edge_service, options=edge_options)\n",
    "\n",
    "# Fem la petició a la web\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "browser.get(url)\n",
    "\n",
    "# Obtenim les cites\n",
    "quotes = browser.find_elements(By.XPATH, \"//div[@class='quote']\")\n",
    "\n",
    "# Separem les cites i creem dataframe\n",
    "quotes_list = []\n",
    "for quote in quotes:\n",
    "    text = quote.find_element(By.XPATH, \"./span[@class='text']\").text\n",
    "    author = quote.find_element(By.XPATH, \"./span/small[@class='author']\").text\n",
    "    tags = [tag.text for tag in quote.find_elements(By.XPATH, \"./div[@class='tags']/a[@class='tag']\")]\n",
    "    quotes_list.append([text, author, tags])\n",
    "\n",
    "# Es guarda en carpeta local\n",
    "df = pd.DataFrame(quotes_list, columns=[\"text\", \"author\", \"tags\"])\n",
    "df.to_csv(output_path / 'quotes_selenium.csv', index=False)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"author\"])\n",
    "    print(row[\"tags\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07656086-f9e1-478f-9b95-0d68db22026e",
   "metadata": {},
   "source": [
    "En el cas de la web, https://www.bolsamadrid.es, podem provar a descarregar la taula de dades de cotizacions de la web del Ibex 35. S'utilitza Selenium degut a la impossiblitat de l'ús de Beautiful Soup per extreure les dades de la taula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a17350-b79f-4dad-aa73-98dc88918bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Índice    Último % Dif.    Máximo    Mínimo       Fecha      Hora  \\\n",
      "0  IBEX 35®  8.833,10  1,31%  8.875,30  8.501,20  20/03/2023  17:38:00   \n",
      "\n",
      "  % Dif. Año  \n",
      "0      7,34%  \n",
      "          Nombre    Último  % Dif.    Máximo    Mínimo      Volumen  \\\n",
      "0        ACCIONA  178,7000   0,96%  179,7000  175,8000       91.995   \n",
      "1   ACCIONA ENER   34,9200   2,28%   35,0200   33,7200      327.669   \n",
      "2       ACERINOX    9,1400   1,76%    9,1960    8,7740    1.016.904   \n",
      "3            ACS   28,5700   1,46%   28,5900   27,5000      547.872   \n",
      "4           AENA  141,9500  -0,32%  143,4500  138,8000      217.473   \n",
      "5        AMADEUS   58,2600  -0,10%   58,7800   56,9600    1.328.070   \n",
      "6    ARCELORMIT.   25,2300   0,92%   25,4200   24,1000      432.187   \n",
      "7    B.SANTANDER    3,2255   2,77%    3,2620    2,9420  118.626.981   \n",
      "8    BA.SABADELL    0,9994   1,71%    1,0110    0,9090   83.069.249   \n",
      "9      BANKINTER    5,5000   1,48%    5,6060    5,1500    8.925.160   \n",
      "10          BBVA    6,2310   3,23%    6,3290    5,7350   35.743.268   \n",
      "11     CAIXABANK    3,6220   3,19%    3,6940    3,3050   29.412.271   \n",
      "12       CELLNEX   33,8600  -0,70%   34,3700   33,6400    1.494.481   \n",
      "13        ENAGAS   17,4150   1,99%   17,5950   17,0700      884.343   \n",
      "14        ENDESA   18,9350   2,21%   18,9350   18,4000    1.548.199   \n",
      "15     FERROVIAL   26,6600   0,57%   26,8400   26,1400    1.110.696   \n",
      "16       FLUIDRA   15,9000  -1,06%   16,0900   15,7400      538.728   \n",
      "17  GRIFOLS CL.A    8,4120  -4,41%    8,7000    8,3660    3.583.613   \n",
      "18           IAG    1,5770   3,78%    1,5930    1,4635   16.985.395   \n",
      "19     IBERDROLA   11,0650   1,33%   11,1250   10,9000   10.696.397   \n",
      "20       INDITEX   28,5100  -0,42%   28,7700   28,0000    3.081.871   \n",
      "21       INDRA A   11,5800   3,21%   11,5800   11,1200      613.877   \n",
      "22  INM.COLONIAL    5,9400   2,24%    5,9600    5,7050    1.202.287   \n",
      "23       LOGISTA   22,7800   2,24%   22,8000   22,0800      288.287   \n",
      "24        MAPFRE    1,8220   1,17%    1,8330    1,7490    6.520.122   \n",
      "25  MELIA HOTELS    5,8150   2,11%    5,8600    5,5350    1.059.758   \n",
      "26        MERLIN    8,2350   1,48%    8,2800    7,9800      880.635   \n",
      "27       NATURGY   26,9600   1,13%   27,1300   26,5600      419.844   \n",
      "28        R.E.C.   15,7900   2,37%   15,9750   15,4200    1.087.519   \n",
      "29        REPSOL   13,7350   1,85%   13,8150   13,0750    6.141.314   \n",
      "30          ROVI   38,0000  -3,89%   39,4200   37,0000      343.415   \n",
      "31         SACYR    2,8240   1,15%    2,8400    2,7220    2.780.530   \n",
      "32       SOLARIA   16,6200  -1,57%   16,7550   16,0700      732.847   \n",
      "33    TELEFONICA    3,7540   1,40%    3,7600    3,6610   11.143.585   \n",
      "34       UNICAJA    0,9965   0,91%    1,0120    0,9200   16.579.117   \n",
      "\n",
      "   Efectivo (miles €)       Fecha    Hora  \n",
      "0           16.404,10  20/03/2023  Cierre  \n",
      "1           11.387,49  20/03/2023  Cierre  \n",
      "2            9.181,29  20/03/2023  Cierre  \n",
      "3           15.523,81  20/03/2023  Cierre  \n",
      "4           30.880,28  20/03/2023  Cierre  \n",
      "5           77.291,15  20/03/2023  Cierre  \n",
      "6           10.715,60  20/03/2023  Cierre  \n",
      "7          368.881,16  20/03/2023  Cierre  \n",
      "8           80.200,28  20/03/2023  Cierre  \n",
      "9           48.386,76  20/03/2023  Cierre  \n",
      "10         217.102,83  20/03/2023  Cierre  \n",
      "11         104.037,72  20/03/2023  Cierre  \n",
      "12          50.635,45  20/03/2023  Cierre  \n",
      "13          15.389,22  20/03/2023  Cierre  \n",
      "14          29.138,14  20/03/2023  Cierre  \n",
      "15          29.529,02  20/03/2023  Cierre  \n",
      "16           8.595,88  20/03/2023  Cierre  \n",
      "17          30.324,36  20/03/2023  Cierre  \n",
      "18          26.064,37  20/03/2023  Cierre  \n",
      "19         118.177,65  20/03/2023  Cierre  \n",
      "20          87.802,00  20/03/2023  Cierre  \n",
      "21           7.011,22  20/03/2023  Cierre  \n",
      "22           7.064,56  20/03/2023  Cierre  \n",
      "23           6.495,96  20/03/2023  Cierre  \n",
      "24          11.713,06  20/03/2023  Cierre  \n",
      "25           6.075,52  20/03/2023  Cierre  \n",
      "26           7.196,86  20/03/2023  Cierre  \n",
      "27          11.302,10  20/03/2023  Cierre  \n",
      "28          17.170,24  20/03/2023  Cierre  \n",
      "29          83.390,06  20/03/2023  Cierre  \n",
      "30          12.986,78  20/03/2023  Cierre  \n",
      "31           7.772,95  20/03/2023  Cierre  \n",
      "32          12.009,22  20/03/2023  Cierre  \n",
      "33          42.233,99  20/03/2023  Cierre  \n",
      "34          16.052,13  20/03/2023  Cierre  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Inicialitzem el servei de Microsoft Edge\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.63'\n",
    "edge_driver_path = os.path.join(os.getcwd(), 'msedgedriver.exe')\n",
    "edge_service = Service(edge_driver_path)\n",
    "\n",
    "# Opcions del driver\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(f'user-agent={user_agent}')\n",
    "edge_options.use_chromium = True\n",
    "edge_options.add_argument(\"--start-maximized\")\n",
    "edge_options.add_argument(\"--disable-extensions\")\n",
    "edge_options.add_argument(\"--disable-gpu\")\n",
    "edge_options.add_argument(\"--disable-infobars\")\n",
    "edge_options.add_argument(\"--headless\")\n",
    "browser = webdriver.Edge(service=edge_service, options=edge_options)\n",
    "\n",
    "\n",
    "# Fem la petició a la web\n",
    "url = \"https://www.bolsasymercados.es/bme-exchange/es/Mercados-y-Cotizaciones/Acciones/Mercado-Continuo/Precios/ibex-35-ES0SI0000005\"\n",
    "browser.get(url)\n",
    "\n",
    "# Obtenim les dades de l'índex\n",
    "rows = []\n",
    "catch = 0\n",
    "while len(rows) == 0: # En ocasions no es descarrega cap informació, eviem que això ocorrega comprovant que rows no està buit\n",
    "    if catch < 10:\n",
    "        table = browser.find_elements(by= By.XPATH, value = '//*[contains(@class,\"index-table\")]//tr')\n",
    "        for row in table:\n",
    "            data = [item.text for item in row.find_elements(by= By.XPATH, value= \".//*[self::td or self::th]\")]\n",
    "            rows.append(data)\n",
    "    else:\n",
    "        pass\n",
    "    catch +=1\n",
    "\n",
    "ibex35 = pd.DataFrame(rows[1:], columns = rows[0])\n",
    "print(ibex35)\n",
    "\n",
    "# Obtenim les dades dels valors que componen l'índex\n",
    "rows = []\n",
    "while len(rows) == 0:\n",
    "    if catch < 10:\n",
    "        table = browser.find_elements(by= By.XPATH, value = '//*[contains(@class,\"shares-table\")]//tr')\n",
    "        for row in table:\n",
    "            data = [item.text for item in row.find_elements(by= By.XPATH, value= \".//*[self::td or self::th]\")]\n",
    "            rows.append(data)\n",
    "    else:\n",
    "        pass\n",
    "    catch +=1\n",
    "        \n",
    "# la primera filera és la que pertany als noms de les columnes\n",
    "stock_indices = pd.DataFrame(rows[1:], columns = rows[0])\n",
    "print(stock_indices)\n",
    "\n",
    "# Guardem els dataframes en un .csv\n",
    "ibex35.to_csv(output_path / \"ibex35.csv\", index=False)\n",
    "stock_indices.to_csv(output_path / \"stock_indices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370558fa-5433-46ee-a20e-05c6ff725004",
   "metadata": {},
   "source": [
    "Finalment, provarem també a descarregar informació de taules que podem trobar a la wikipedia, com és el cas de les taules de dades climàtiques de diferents ciutats. Per exemple, de la ciutat de València."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134da4d1-5247-4797-8314-1eb4f555d2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Jan         Feb         Mar  \\\n",
      "Record high °C (°F)                  25.8(78.4)  29.0(84.2)  33.2(91.8)   \n",
      "Average high °C (°F)                 16.4(61.5)  17.1(62.8)  19.3(66.7)   \n",
      "Daily mean °C (°F)                   11.9(53.4)  12.7(54.9)  14.6(58.3)   \n",
      "Average low °C (°F)                   7.1(44.8)   7.8(46.0)   9.7(49.5)   \n",
      "Record low °C (°F)                   −2.6(27.3)  −1.2(29.8)   1.2(34.2)   \n",
      "Average precipitation mm (inches)       37(1.5)     36(1.4)     33(1.3)   \n",
      "Average precipitation days (≥ 1 mm)         4.4         3.9         3.6   \n",
      "Mean monthly sunshine hours                 171         171         215   \n",
      "\n",
      "                                            Apr          May          Jun  \\\n",
      "Record high °C (°F)                  33.5(92.3)  42.0(107.6)  39.3(102.7)   \n",
      "Average high °C (°F)                 20.8(69.4)   23.4(74.1)   27.1(80.8)   \n",
      "Daily mean °C (°F)                   16.2(61.2)   19.0(66.2)   22.9(73.2)   \n",
      "Average low °C (°F)                  11.5(52.7)   14.6(58.3)   18.6(65.5)   \n",
      "Record low °C (°F)                    3.0(37.4)    6.0(42.8)   10.6(51.1)   \n",
      "Average precipitation mm (inches)       38(1.5)      39(1.5)      22(0.9)   \n",
      "Average precipitation days (≥ 1 mm)         4.8          4.3          2.6   \n",
      "Mean monthly sunshine hours                 234          259          276   \n",
      "\n",
      "                                             Jul          Aug          Sep  \\\n",
      "Record high °C (°F)                  41.8(107.2)  43.0(109.4)  38.4(101.1)   \n",
      "Average high °C (°F)                  29.7(85.5)   30.2(86.4)   27.9(82.2)   \n",
      "Daily mean °C (°F)                    25.6(78.1)   26.1(79.0)   23.5(74.3)   \n",
      "Average low °C (°F)                   21.5(70.7)   21.9(71.4)   19.1(66.4)   \n",
      "Record low °C (°F)                    16.0(60.8)   16.2(61.2)   11.6(52.9)   \n",
      "Average precipitation mm (inches)         8(0.3)      20(0.8)      70(2.8)   \n",
      "Average precipitation days (≥ 1 mm)          1.1          2.4          5.0   \n",
      "Mean monthly sunshine hours                  315          288          235   \n",
      "\n",
      "                                            Oct         Nov         Dec  \\\n",
      "Record high °C (°F)                  35.6(96.1)  32.0(89.6)  25.2(77.4)   \n",
      "Average high °C (°F)                 24.3(75.7)  19.8(67.6)  17.0(62.6)   \n",
      "Daily mean °C (°F)                   19.7(67.5)  15.3(59.5)  12.6(54.7)   \n",
      "Average low °C (°F)                  15.2(59.4)  10.8(51.4)   8.1(46.6)   \n",
      "Record low °C (°F)                    6.3(43.3)   1.6(34.9)  −0.3(31.5)   \n",
      "Average precipitation mm (inches)       77(3.0)     47(1.9)     48(1.9)   \n",
      "Average precipitation days (≥ 1 mm)         5.0         4.3         4.8   \n",
      "Mean monthly sunshine hours                 202         167         155   \n",
      "\n",
      "                                            Year  \n",
      "Record high °C (°F)                  43.0(109.4)  \n",
      "Average high °C (°F)                  22.8(73.0)  \n",
      "Daily mean °C (°F)                    18.3(64.9)  \n",
      "Average low °C (°F)                   13.8(56.8)  \n",
      "Record low °C (°F)                    −2.6(27.3)  \n",
      "Average precipitation mm (inches)      475(18.7)  \n",
      "Average precipitation days (≥ 1 mm)         46.3  \n",
      "Mean monthly sunshine hours                2,696  \n"
     ]
    }
   ],
   "source": [
    "# Petició a la web\n",
    "url = \"https://en.wikipedia.org/wiki/Valencia\"\n",
    "page = requests.get(url)\n",
    "\n",
    "# Creem objecte beautifulsoup\n",
    "page_content  = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Cerquem la taula en la web\n",
    "table = page_content.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Creem dataframe\n",
    "rows = table.find_all(\"tr\")\n",
    "data = []\n",
    "columns = []\n",
    "index_names = []\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "    # Obtenim les cel·les que ens interessen.\n",
    "    head = row.find_all(\"th\") # Conté els noms de les columnes i el de les files\n",
    "    cells = row.find_all(\"td\")  # Els valors de les cel·les\n",
    "    \n",
    "    # Processem els noms de les columnes i el de les files\n",
    "    if head:\n",
    "        row_values = [cell.text.strip() for cell in head]\n",
    "        if 'Jan' in row_values:\n",
    "            months = row_values\n",
    "        elif len(row_values[0]) < 40:\n",
    "            index_names.append(row_values)\n",
    "    \n",
    "    # Processem els valors de les cel·les\n",
    "    if cells:\n",
    "        row_values = [cell.text.strip() for cell in cells]\n",
    "        if 'Source' not in row_values[0]:\n",
    "            data.append(row_values)\n",
    "\n",
    "index_names_l = list(itertools.chain.from_iterable(index_names))\n",
    "        \n",
    "# S'el·limina de la llista de mesos la paraula mesos ja que no forma part d'una columna de dades\n",
    "months = [month for month in months if 'Month' not in month]\n",
    "\n",
    "# Convertim les llistes en dataframe i el descarreguem en un csv\n",
    "df = pd.DataFrame(data, index=index_names_l, columns=months)\n",
    "df.to_csv(output_path / \"valencia_climate_data.csv\", index=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed58bd2-f52b-4688-981f-bac5a565021e",
   "metadata": {},
   "source": [
    "#### Exercici 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6834a-ffb0-473f-af41-33ab75d700ee",
   "metadata": {},
   "source": [
    "Els documents words es troben a la carpeta Exercici 2 en el repositori."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09c830-2267-4b88-8881-b5dbcaf88788",
   "metadata": {},
   "source": [
    "#### Exercici 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfdda4-1a87-48d8-ac3e-3bbda6fbae55",
   "metadata": {},
   "source": [
    "A la web de l'Aemet es publiquen els mapes sinoptics. En concret, l'anàlisis i la predicció fins a 48 hores. Aquesta s'actualitza dos voltes cada dia però l'Aemet no ofereix la possibilitat de descarregar els mapes publicats anteriorment i es podria automatitzar la descàrrega dels mapes tant amb Selenium com amb Scrapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93432bc4-7fe5-4f36-b4d1-d060f1629058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapa 2023032012+000_ww_gpx0a200.gif descarregat.\n",
      "Mapa 2023032012+012_ww_g1x0a212.gif descarregat.\n",
      "Mapa 2023032012+024_ww_g1x0a2d1.gif descarregat.\n",
      "Mapa 2023032012+036_ww_g1x0a2c1.gif descarregat.\n",
      "Mapa 2023032012+048_ww_g1x0a2d2.gif descarregat.\n",
      "Mapa 2023032012+060_ww_g1x0a2c2.gif descarregat.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "\n",
    "# Inicialitzem el servei de Microsoft Edge\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.63'\n",
    "edge_driver_path = os.path.join(os.getcwd(), 'msedgedriver.exe')\n",
    "edge_service = Service(edge_driver_path)\n",
    "\n",
    "# Opcions del driver\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(f'user-agent={user_agent}')\n",
    "edge_options.use_chromium = True\n",
    "edge_options.add_argument(\"--start-maximized\")\n",
    "edge_options.add_argument(\"--disable-extensions\")\n",
    "edge_options.add_argument(\"--disable-gpu\")\n",
    "edge_options.add_argument(\"--disable-infobars\")\n",
    "edge_options.add_argument(\"--headless\")\n",
    "browser = webdriver.Edge(service=edge_service, options=edge_options)\n",
    "\n",
    "browser.get(\"https://www.aemet.es/ca/eltiempo/prediccion/mapa_frentes\")\n",
    "\n",
    "# Es cerquen les imatges que corresponen als mapes\n",
    "links = browser.find_elements(by=By.CSS_SELECTOR, value=\"img.lazyOwl\")\n",
    "\n",
    "for i in range(len(links)):\n",
    "    link = links[i]\n",
    "    if i==0 or i==5:\n",
    "        url_map = link.get_attribute(\"src\")\n",
    "    else:\n",
    "        url_map = link.get_attribute(\"data-src\")\n",
    "        url_map = 'https://www.aemet.es' + url_map \n",
    "\n",
    "    # El nom de l'arxiu serà la última part del link a la imatge, després de l'últim '/'.\n",
    "    file_name = url_map.split(\"/\")[-1]\n",
    "    \n",
    "    # Es guarden a una carpeta local\n",
    "    file_path = \"mapes_selenium/\" + file_name\n",
    "    output_map = output_path / file_path\n",
    "    output_map = Path(output_map)\n",
    "    with open(output_map, \"wb\") as archivo:\n",
    "        archivo.write(requests.get(url_map).content)\n",
    "        print(f\"Mapa {file_name} descarregat.\")\n",
    "        \n",
    "# Es tanca Selenium\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e249f3a-b3a6-4991-9ab0-cfc508c8d728",
   "metadata": {},
   "source": [
    "Ara adaptarem el codi a Scrapy. Per a això, crearem en el directori on tenim l'arxiu del notebook jupyter, el codi a executar, el cual es mostra a continuació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756f5c3-6f34-4e0a-bca2-f5be069dfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = 'D:/Sistema_Solar/Python/itacademy/itacademy-datascience/sprint10/output/'\n",
    "output_path = Path(output_path)\n",
    "\n",
    "class AEMETSpider(scrapy.Spider):\n",
    "    name = 'aemet_spider'\n",
    "    start_urls = ['https://www.aemet.es/ca/eltiempo/prediccion/mapa_frentes']\n",
    "\n",
    "    # Configuració per optimitzar les peticions\n",
    "    custom_settings = {\n",
    "        'CONCURRENT_REQUESTS': 1, # Evite fer massa peticions a la vegada\n",
    "        'AUTOTHROTTLE_ENABLED': True, # Controla la velocitat de les peticions\n",
    "        'DOWNLOAD_DELAY': 1 # Temps entre peticions\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        links = response.css(\"img.lazyOwl\")\n",
    "\n",
    "        for link in links:\n",
    "\n",
    "            url_map = link.attrib[\"data-src\"]\n",
    "            url_map = 'https://www.aemet.es' + url_map\n",
    "            \n",
    "            # El nom de l'arxiu serà la última part del link a la imatge, després de l'últim '/'.\n",
    "            file_name = url_map.split(\"/\")[-1]\n",
    "            \n",
    "            # Es guarden a una carpeta local\n",
    "            file_path = \"mapes_scrapy/\" + file_name\n",
    "            output_map = output_path / file_path\n",
    "            output_map = Path(output_map)\n",
    "            with open(output_map, \"wb\") as archivo:\n",
    "                archivo.write(requests.get(url_map).content)\n",
    "                print(f\"Mapa {file_name} descarregat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef39517-c885-4db1-a666-681631ad1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapa 2023032012+000_ww_gpx0a200.gif descarregat.\n",
      "Mapa 2023032012+012_ww_g1x0a212.gif descarregat.\n",
      "Mapa 2023032012+024_ww_g1x0a2d1.gif descarregat.\n",
      "Mapa 2023032012+036_ww_g1x0a2c1.gif descarregat.\n",
      "Mapa 2023032012+048_ww_g1x0a2d2.gif descarregat.\n",
      "Mapa 2023032012+060_ww_g1x0a2c2.gif descarregat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:26:51 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scrapybot)\n",
      "2023-03-20 23:26:51 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.7.0, w3lib 1.21.0, Twisted 22.2.0, Python 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1t  7 Feb 2023), cryptography 38.0.4, Platform Windows-10-10.0.19045-SP0\n",
      "2023-03-20 23:26:51 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'AUTOTHROTTLE_ENABLED': True,\n",
      " 'CONCURRENT_REQUESTS': 1,\n",
      " 'DOWNLOAD_DELAY': 1,\n",
      " 'SPIDER_LOADER_WARN_ONLY': True}\n",
      "2023-03-20 23:26:51 [py.warnings] WARNING: D:\\Programes\\Anaconda3\\lib\\site-packages\\scrapy\\utils\\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-03-20 23:26:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2023-03-20 23:26:51 [scrapy.extensions.telnet] INFO: Telnet Password: 31182e251a394b51\n",
      "2023-03-20 23:26:52 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats',\n",
      " 'scrapy.extensions.throttle.AutoThrottle']\n",
      "2023-03-20 23:26:54 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-03-20 23:26:54 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-03-20 23:26:54 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-03-20 23:26:54 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-03-20 23:26:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-03-20 23:26:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-03-20 23:26:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.aemet.es/ca/eltiempo/prediccion/mapa_frentes> (referer: None)\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023032012+000_ww_gpx0a200.gif HTTP/1.1\" 200 128289\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023032012+012_ww_g1x0a212.gif HTTP/1.1\" 200 143453\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023032012+024_ww_g1x0a2d1.gif HTTP/1.1\" 200 143679\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023032012+036_ww_g1x0a2c1.gif HTTP/1.1\" 200 138085\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-20 23:26:55 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023032012+048_ww_g1x0a2d2.gif HTTP/1.1\" 200 141125\n",
      "2023-03-20 23:26:56 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.aemet.es:443\n",
      "2023-03-20 23:26:56 [urllib3.connectionpool] DEBUG: https://www.aemet.es:443 \"GET /imagenes_d/eltiempo/prediccion/mapa_frentes/2023032012+060_ww_g1x0a2c2.gif HTTP/1.1\" 200 138481\n",
      "2023-03-20 23:26:56 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-03-20 23:26:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 257,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 10770,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 1.150164,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 3, 20, 22, 26, 56, 164524),\n",
      " 'httpcompression/response_bytes': 49289,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/DEBUG': 14,\n",
      " 'log_count/INFO': 10,\n",
      " 'log_count/WARNING': 1,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2023, 3, 20, 22, 26, 55, 14360)}\n",
      "2023-03-20 23:26:56 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "# Executem l'arxiu amb el codi.\n",
    "!scrapy runspider -a file_path=aemet_spider.py aemet_spider.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
